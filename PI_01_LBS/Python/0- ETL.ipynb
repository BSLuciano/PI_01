{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Procesamiento de los datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar todas las hojas del archivo excel\n",
    "path = r'C:\\Users\\barce\\OneDrive\\Escritorio\\HENRY\\HENRY_Course\\1- Data_Science\\Proyectos\\1- Individual\\PI - 1\\PI01_DATA_ENGINEERING-main\\Datasets\\precios_semanas_20200419_20200426.xlsx'\n",
    "df_1 = pd.read_excel(path, sheet_name= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['precios_20200426_20200426', 'precios_20200419_20200419'])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_h1 = df_1['precios_20200426_20200426']\n",
    "df_1_h2 = df_1['precios_20200419_20200419']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Union hojas en un df\n",
    "#df_1_concat = pd.concat(df_1, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_2 = r'C:\\Users\\barce\\OneDrive\\Escritorio\\HENRY\\HENRY_Course\\1- Data_Science\\Proyectos\\1- Individual\\PI - 1\\PI01_DATA_ENGINEERING-main\\Datasets\\precios_semana_20200413.csv' \n",
    "df_2 = pd.read_csv(path_2, encoding='utf-16-le', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_3 = r'C:\\Users\\barce\\OneDrive\\Escritorio\\HENRY\\HENRY_Course\\1- Data_Science\\Proyectos\\1- Individual\\PI - 1\\PI01_DATA_ENGINEERING-main\\Datasets\\precios_semana_20200503.json'\n",
    "df_3 = pd.read_json(path_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path_4 = r'C:\\Users\\barce\\OneDrive\\Escritorio\\HENRY\\HENRY_Course\\1- Data_Science\\Proyectos\\1- Individual\\PI - 1\\PI01_DATA_ENGINEERING-main\\Datasets\\precios_semana_20200518.txt'\n",
    "df_4 = pd.read_csv(path_4, sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de archivo .parquet\n",
    "path_5 = r'C:\\Users\\barce\\OneDrive\\Escritorio\\HENRY\\HENRY_Course\\1- Data_Science\\Proyectos\\1- Individual\\PI - 1\\PI01_DATA_ENGINEERING-main\\Datasets\\producto.parquet'\n",
    "df_producto = pd.read_parquet(path_5, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_6 = r'C:\\Users\\barce\\OneDrive\\Escritorio\\HENRY\\HENRY_Course\\1- Data_Science\\Proyectos\\1- Individual\\PI - 1\\PI01_DATA_ENGINEERING-main\\Datasets\\sucursal.csv'\n",
    "df_sucursal = pd.read_csv(path_6, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Valores duplicados: Identificación y Tratamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario de DataFrames\n",
    "\n",
    "dicc = {'df_1_h1':df_1_h1, 'df_1_h2':df_1_h2, 'df_2':df_2,\n",
    "         'df_3':df_3, 'df_4':df_4, 'df_sucursal':df_sucursal, 'df_producto':df_producto}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_1_h1     Cantidad Registros Duplicados: 4217\n",
      "df_1_h2     Cantidad Registros Duplicados: 0\n",
      "df_2     Cantidad Registros Duplicados: 32\n",
      "df_3     Cantidad Registros Duplicados: 0\n",
      "df_4     Cantidad Registros Duplicados: 189\n",
      "df_sucursal     Cantidad Registros Duplicados: 0\n",
      "df_producto     Cantidad Registros Duplicados: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dicc = {'df_1_h1':df_1_h1, 'df_1_h2':df_1_h2, 'df_2':df_2,\n",
    "         'df_3':df_3, 'df_4':df_4, 'df_sucursal':df_sucursal, 'df_producto':df_producto}\n",
    "for key in dicc:\n",
    "    print(key,'   ','Cantidad Registros Duplicados:',len(dicc[key])-len(dicc[key].drop_duplicates()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procede a eliminar los registros duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_1_h1     Cantidad Registros Duplicados: 0\n",
      "df_1_h2     Cantidad Registros Duplicados: 0\n",
      "df_2     Cantidad Registros Duplicados: 0\n",
      "df_3     Cantidad Registros Duplicados: 0\n",
      "df_4     Cantidad Registros Duplicados: 0\n",
      "df_sucursal     Cantidad Registros Duplicados: 0\n",
      "df_producto     Cantidad Registros Duplicados: 0\n"
     ]
    }
   ],
   "source": [
    "# Verificación\n",
    "dicc = {'df_1_h1':df_1_h1, 'df_1_h2':df_1_h2, 'df_2':df_2,\n",
    "         'df_3':df_3, 'df_4':df_4, 'df_sucursal':df_sucursal, 'df_producto':df_producto}\n",
    "for key in dicc:\n",
    "    dicc[key].drop_duplicates(inplace=True)\n",
    "    print(key,'   ','Cantidad Registros Duplicados:',len(dicc[key])-len(dicc[key].drop_duplicates()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Valores Faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_1_h1   Cantidad Registros Nulos: \n",
      " precio         1639\n",
      "sucursal_id       0\n",
      "producto_id    9302\n",
      "dtype: int64 \n",
      "\n",
      "df_1_h1   porcentaje: % \n",
      " precio         0.35\n",
      "sucursal_id    0.00\n",
      "producto_id    1.96\n",
      "dtype: float64 \n",
      "\n",
      "df_1_h2   Cantidad Registros Nulos: \n",
      " precio         1807\n",
      "sucursal_id       0\n",
      "producto_id       0\n",
      "dtype: int64 \n",
      "\n",
      "df_1_h2   porcentaje: % \n",
      " precio         0.39\n",
      "sucursal_id    0.00\n",
      "producto_id    0.00\n",
      "dtype: float64 \n",
      "\n",
      "df_2   Cantidad Registros Nulos: \n",
      " precio         1\n",
      "producto_id    3\n",
      "sucursal_id    3\n",
      "dtype: int64 \n",
      "\n",
      "df_2   porcentaje: % \n",
      " precio         0.0\n",
      "producto_id    0.0\n",
      "sucursal_id    0.0\n",
      "dtype: float64 \n",
      "\n",
      "df_3   Cantidad Registros Nulos: \n",
      " precio         0\n",
      "producto_id    0\n",
      "sucursal_id    0\n",
      "dtype: int64 \n",
      "\n",
      "df_3   porcentaje: % \n",
      " precio         0.0\n",
      "producto_id    0.0\n",
      "sucursal_id    0.0\n",
      "dtype: float64 \n",
      "\n",
      "df_4   Cantidad Registros Nulos: \n",
      " precio         1957\n",
      "producto_id       3\n",
      "sucursal_id       3\n",
      "dtype: int64 \n",
      "\n",
      "df_4   porcentaje: % \n",
      " precio         0.47\n",
      "producto_id    0.00\n",
      "sucursal_id    0.00\n",
      "dtype: float64 \n",
      "\n",
      "df_sucursal   Cantidad Registros Nulos: \n",
      " id                     0\n",
      "comercioId             0\n",
      "banderaId              0\n",
      "banderaDescripcion     0\n",
      "comercioRazonSocial    0\n",
      "provincia              0\n",
      "localidad              0\n",
      "direccion              0\n",
      "lat                    0\n",
      "lng                    0\n",
      "sucursalNombre         0\n",
      "sucursalTipo           0\n",
      "dtype: int64 \n",
      "\n",
      "df_sucursal   porcentaje: % \n",
      " id                     0.0\n",
      "comercioId             0.0\n",
      "banderaId              0.0\n",
      "banderaDescripcion     0.0\n",
      "comercioRazonSocial    0.0\n",
      "provincia              0.0\n",
      "localidad              0.0\n",
      "direccion              0.0\n",
      "lat                    0.0\n",
      "lng                    0.0\n",
      "sucursalNombre         0.0\n",
      "sucursalTipo           0.0\n",
      "dtype: float64 \n",
      "\n",
      "df_producto   Cantidad Registros Nulos: \n",
      " id                  0\n",
      "marca               2\n",
      "nombre              2\n",
      "presentacion        2\n",
      "categoria1      72034\n",
      "categoria2      72034\n",
      "categoria3      72034\n",
      "dtype: int64 \n",
      "\n",
      "df_producto   porcentaje: % \n",
      " id               0.00\n",
      "marca            0.00\n",
      "nombre           0.00\n",
      "presentacion     0.00\n",
      "categoria1      99.99\n",
      "categoria2      99.99\n",
      "categoria3      99.99\n",
      "dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "dicc = {'df_1_h1':df_1_h1, 'df_1_h2':df_1_h2, 'df_2':df_2,\n",
    "         'df_3':df_3, 'df_4':df_4, 'df_sucursal':df_sucursal, 'df_producto':df_producto}\n",
    "for key in dicc:\n",
    "\n",
    "    porcentaje_null = round(dicc[key].isnull().sum()*100/dicc[key].shape[0],2)\n",
    "    print(key,' ','Cantidad Registros Nulos:','\\n',dicc[key].isnull().sum(),'\\n')\n",
    "    print(key,' ','porcentaje: %','\\n',porcentaje_null,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede apreciar que la cantidad de valores faltantes (excluidos los de categorías) no es significante en comparación con la cantidad de registros totales, por lo que se puede esperar que lo datos no se vearán afectados, como medida ante esto he decidido sólo reemplazar esos valores faltantes con '0'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicc = {'df_1_h1':df_1_h1, 'df_1_h2':df_1_h2, 'df_2':df_2,\n",
    "         'df_3':df_3, 'df_4':df_4, 'df_sucursal':df_sucursal, 'df_producto':df_producto}\n",
    "for key in dicc:\n",
    "    for e in dicc[key]:\n",
    "        dicc[key][e].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Tipo de Dato por DataFrame y Columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_1_h1   precio   Tipo de Dato: float64 \n",
      "\n",
      "df_1_h1   sucursal_id   Tipo de Dato: object \n",
      "\n",
      "df_1_h1   producto_id   Tipo de Dato: float64 \n",
      "\n",
      "df_1_h2   precio   Tipo de Dato: float64 \n",
      "\n",
      "df_1_h2   sucursal_id   Tipo de Dato: object \n",
      "\n",
      "df_1_h2   producto_id   Tipo de Dato: object \n",
      "\n",
      "df_2   precio   Tipo de Dato: float64 \n",
      "\n",
      "df_2   producto_id   Tipo de Dato: object \n",
      "\n",
      "df_2   sucursal_id   Tipo de Dato: object \n",
      "\n",
      "df_3   precio   Tipo de Dato: object \n",
      "\n",
      "df_3   producto_id   Tipo de Dato: object \n",
      "\n",
      "df_3   sucursal_id   Tipo de Dato: object \n",
      "\n",
      "df_4   precio   Tipo de Dato: float64 \n",
      "\n",
      "df_4   producto_id   Tipo de Dato: object \n",
      "\n",
      "df_4   sucursal_id   Tipo de Dato: object \n",
      "\n",
      "df_sucursal   id   Tipo de Dato: object \n",
      "\n",
      "df_sucursal   comercioId   Tipo de Dato: int64 \n",
      "\n",
      "df_sucursal   banderaId   Tipo de Dato: int64 \n",
      "\n",
      "df_sucursal   banderaDescripcion   Tipo de Dato: object \n",
      "\n",
      "df_sucursal   comercioRazonSocial   Tipo de Dato: object \n",
      "\n",
      "df_sucursal   provincia   Tipo de Dato: object \n",
      "\n",
      "df_sucursal   localidad   Tipo de Dato: object \n",
      "\n",
      "df_sucursal   direccion   Tipo de Dato: object \n",
      "\n",
      "df_sucursal   lat   Tipo de Dato: float64 \n",
      "\n",
      "df_sucursal   lng   Tipo de Dato: float64 \n",
      "\n",
      "df_sucursal   sucursalNombre   Tipo de Dato: object \n",
      "\n",
      "df_sucursal   sucursalTipo   Tipo de Dato: object \n",
      "\n",
      "df_producto   id   Tipo de Dato: object \n",
      "\n",
      "df_producto   marca   Tipo de Dato: object \n",
      "\n",
      "df_producto   nombre   Tipo de Dato: object \n",
      "\n",
      "df_producto   presentacion   Tipo de Dato: object \n",
      "\n",
      "df_producto   categoria1   Tipo de Dato: object \n",
      "\n",
      "df_producto   categoria2   Tipo de Dato: object \n",
      "\n",
      "df_producto   categoria3   Tipo de Dato: object \n",
      "\n"
     ]
    }
   ],
   "source": [
    "dicc = {'df_1_h1':df_1_h1, 'df_1_h2':df_1_h2, 'df_2':df_2,\n",
    "         'df_3':df_3, 'df_4':df_4, 'df_sucursal':df_sucursal, 'df_producto':df_producto}\n",
    "for key in dicc:\n",
    "    e=0\n",
    "    while e < dicc[key].columns.shape[0]:\n",
    "        for i in dicc[key]:\n",
    "            \n",
    "            print(key,' ',dicc[key].columns[e],' ','Tipo de Dato:',dicc[key][i].dtype,'\\n')\n",
    "            e+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Cambiar orden de las columnas del archivo XLSX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_h1 = df_1_h1[['precio','producto_id','sucursal_id']]\n",
    "df_1_h2 = df_1_h2[['precio','producto_id','sucursal_id']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Cambiar nombre de la columna id del df_producto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_producto = df_producto.rename(columns={'id':'producto_id'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Solucionar errores en producto_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decidí dejar de la estos cambios hasta lograr una mejor evaluación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se quitan los primeros dígitos del Id para obtener el código EAN de 13 dígitos\n",
    "df_1_h2.producto_id = df_1_h2.producto_id.astype('str')\n",
    "df_1_h2.producto_id = df_1_h2.producto_id.apply(lambda x: x.split('-')[-1])\n",
    "df_1_h2.producto_id = df_1_h2.producto_id.apply(lambda x: x.zfill(13))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_1_h1.producto_id = df_1_h2.producto_id.astype('str')\n",
    "df_1_h2.producto_id = df_1_h2.producto_id.apply(lambda x: x.zfill(13))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_2.producto_id = df_2.producto_id.astype('str')\n",
    "df_2.producto_id = df_2.producto_id.apply(lambda x: x.split('-')[-1])\n",
    "df_1_h2.producto_id = df_1_h2.producto_id.apply(lambda x: x.zfill(13))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_3.producto_id = df_3.producto_id.astype('str')\n",
    "df_3.producto_id = df_3.producto_id.apply(lambda x: x.split('-')[-1])\n",
    "df_3.producto_id = df_3.producto_id.apply(lambda x: x.zfill(13))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_producto.producto_id = df_producto.producto_id.astype('str')\n",
    "df_producto.producto_id = df_producto.producto_id.apply(lambda x: x.split('-')[-1])\n",
    "df_producto.producto_id = df_producto.producto_id.apply(lambda x: x.zfill(13))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Reducir cantidad de decimales de columna precio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar str '' con 0, cambiar type \n",
    "df_3.precio = df_3.precio.replace('',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.precio = df_2.precio.astype(float);\n",
    "df_1_h1.precio = df_1_h1.precio.astype(float);\n",
    "df_1_h2.precio = df_1_h2.precio.astype(float);\n",
    "df_3.precio = df_3.precio.astype(float);\n",
    "df_4.precio = df_4.precio.astype(float);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_1_h1   Cantidad Registros Nulos: \n",
      " precio         0\n",
      "producto_id    0\n",
      "sucursal_id    0\n",
      "dtype: int64 \n",
      "\n",
      "df_1_h1   porcentaje: % \n",
      " precio         0.0\n",
      "producto_id    0.0\n",
      "sucursal_id    0.0\n",
      "dtype: float64 \n",
      "\n",
      "df_1_h2   Cantidad Registros Nulos: \n",
      " precio         0\n",
      "producto_id    0\n",
      "sucursal_id    0\n",
      "dtype: int64 \n",
      "\n",
      "df_1_h2   porcentaje: % \n",
      " precio         0.0\n",
      "producto_id    0.0\n",
      "sucursal_id    0.0\n",
      "dtype: float64 \n",
      "\n",
      "df_2   Cantidad Registros Nulos: \n",
      " precio         0\n",
      "producto_id    0\n",
      "sucursal_id    0\n",
      "dtype: int64 \n",
      "\n",
      "df_2   porcentaje: % \n",
      " precio         0.0\n",
      "producto_id    0.0\n",
      "sucursal_id    0.0\n",
      "dtype: float64 \n",
      "\n",
      "df_3   Cantidad Registros Nulos: \n",
      " precio         0\n",
      "producto_id    0\n",
      "sucursal_id    0\n",
      "dtype: int64 \n",
      "\n",
      "df_3   porcentaje: % \n",
      " precio         0.0\n",
      "producto_id    0.0\n",
      "sucursal_id    0.0\n",
      "dtype: float64 \n",
      "\n",
      "df_4   Cantidad Registros Nulos: \n",
      " precio         0\n",
      "producto_id    0\n",
      "sucursal_id    0\n",
      "dtype: int64 \n",
      "\n",
      "df_4   porcentaje: % \n",
      " precio         0.0\n",
      "producto_id    0.0\n",
      "sucursal_id    0.0\n",
      "dtype: float64 \n",
      "\n",
      "df_sucursal   Cantidad Registros Nulos: \n",
      " id                     0\n",
      "comercioId             0\n",
      "banderaId              0\n",
      "banderaDescripcion     0\n",
      "comercioRazonSocial    0\n",
      "provincia              0\n",
      "localidad              0\n",
      "direccion              0\n",
      "lat                    0\n",
      "lng                    0\n",
      "sucursalNombre         0\n",
      "sucursalTipo           0\n",
      "dtype: int64 \n",
      "\n",
      "df_sucursal   porcentaje: % \n",
      " id                     0.0\n",
      "comercioId             0.0\n",
      "banderaId              0.0\n",
      "banderaDescripcion     0.0\n",
      "comercioRazonSocial    0.0\n",
      "provincia              0.0\n",
      "localidad              0.0\n",
      "direccion              0.0\n",
      "lat                    0.0\n",
      "lng                    0.0\n",
      "sucursalNombre         0.0\n",
      "sucursalTipo           0.0\n",
      "dtype: float64 \n",
      "\n",
      "df_producto   Cantidad Registros Nulos: \n",
      " producto_id     0\n",
      "marca           0\n",
      "nombre          0\n",
      "presentacion    0\n",
      "categoria1      0\n",
      "categoria2      0\n",
      "categoria3      0\n",
      "dtype: int64 \n",
      "\n",
      "df_producto   porcentaje: % \n",
      " producto_id     0.0\n",
      "marca           0.0\n",
      "nombre          0.0\n",
      "presentacion    0.0\n",
      "categoria1      0.0\n",
      "categoria2      0.0\n",
      "categoria3      0.0\n",
      "dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Se detectan nuevamente valores nulos\n",
    "dicc = {'df_1_h1':df_1_h1, 'df_1_h2':df_1_h2, 'df_2':df_2,\n",
    "         'df_3':df_3, 'df_4':df_4, 'df_sucursal':df_sucursal, 'df_producto':df_producto}\n",
    "for key in dicc:\n",
    "\n",
    "    porcentaje_null = round(dicc[key].isnull().sum()*100/dicc[key].shape[0],2)\n",
    "    print(key,' ','Cantidad Registros Nulos:','\\n',dicc[key].isnull().sum(),'\\n')\n",
    "    print(key,' ','porcentaje: %','\\n',porcentaje_null,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quitar registro nulos de df_1_h1.producto_id\n",
    "df_1_h1.producto_id.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.precio = df_2.precio.round(2)\n",
    "df_1_h1.precio = df_1_h1.precio.round(2)\n",
    "df_1_h2.precio = df_1_h2.precio.round(2)\n",
    "df_3.precio = df_3.precio.round(2)\n",
    "df_4.precio = df_4.precio.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Corrección sucursal_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algunos registros contienen formato datetime y se presentan como fecha y hora. Además los componentes del id están en orden inverso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para normalizar los id\n",
    "\n",
    "df_1_h2.sucursal_id = df_1_h2.sucursal_id.astype(str)\n",
    "df_2.sucursal_id = df_2.sucursal_id.astype(str)\n",
    "\n",
    "def mod_id_suc (x):\n",
    "    if ' 00:00:00' in x:\n",
    "        x = x.replace(' 00:00:00','')\n",
    "        val_1 = x.split('-')[0]\n",
    "        val_2 = x.split('-')[1]\n",
    "        val_3 = x.split('-')[2]\n",
    "       \n",
    "        x = val_3 + '-' + val_2 + '-' + val_1\n",
    "    return x\n",
    "\n",
    "df_2.sucursal_id = df_2.sucursal_id.apply(mod_id_suc)\n",
    "df_1_h2.sucursal_id = df_1_h2.sucursal_id.apply(mod_id_suc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Crear columnas con Fechas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - - Extracción de fechas de los nombres de los archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraer el texto del cual se sacará la fecha\n",
    "df_2_texto = os.path.split(path_2)[1]\n",
    "df_3_texto = os.path.split(path_3)[1]\n",
    "df_4_texto = os.path.split(path_4)[1]\n",
    "\n",
    "lista = list(df_1.keys())\n",
    "df_1_h1_texto = lista[0]\n",
    "df_1_h2_texto = lista[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraer la fecha del texto\n",
    "df_2_fecha = [int(df_2_semana) for df_2_semana in re.findall(r'\\d+', df_2_texto)][0]\n",
    "df_3_fecha = [int(df_3_semana) for df_3_semana in re.findall(r'\\d+', df_3_texto)][0]\n",
    "df_4_fecha = [int(df_4_semana) for df_4_semana in re.findall(r'\\d+', df_4_texto)][0]\n",
    "df_1_h1_fecha = [int(df_2_semana) for df_2_semana in re.findall(r'\\d+', df_1_h1_texto)][0]\n",
    "df_1_h2_fecha = [int(df_2_semana) for df_2_semana in re.findall(r'\\d+', df_1_h2_texto)][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2['fecha_semana'] = df_2_fecha\n",
    "df_3['fecha_semana'] = df_3_fecha\n",
    "df_4['fecha_semana'] = df_4_fecha\n",
    "df_1_h1['fecha_semana'] = df_1_h1_fecha\n",
    "df_1_h2['fecha_semana'] = df_1_h2_fecha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Verificar datos no duplicados en id de df_sucursal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_sucursal.id)-len(df_sucursal.id.drop_duplicates())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Exportar DataFrames a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ubicar csv en programdata para poder acceder a ellos desde mysql\n",
    "df_1_h1.to_csv(r'C:\\ProgramData\\MySQL\\MySQL Server 8.0\\Uploads\\PI-01\\precios_semanas_20200426_20200426_mod_h1.csv', index=False)\n",
    "df_1_h2.to_csv(r'C:\\ProgramData\\MySQL\\MySQL Server 8.0\\Uploads\\PI-01\\precios_semanas_20200419_20200419_mod_h2.csv', index=False)\n",
    "df_2.to_csv(r'C:\\ProgramData\\MySQL\\MySQL Server 8.0\\Uploads\\PI-01\\precios_semana_20200413_mod.csv', index=False)\n",
    "df_3.to_csv(r'C:\\ProgramData\\MySQL\\MySQL Server 8.0\\Uploads\\PI-01\\precios_semana_20200503_mod.csv', index=False)\n",
    "df_4.to_csv(r'C:\\ProgramData\\MySQL\\MySQL Server 8.0\\Uploads\\PI-01\\precios_semana_20200518_mod.csv', index=False)\n",
    "df_producto.to_csv(r'C:\\ProgramData\\MySQL\\MySQL Server 8.0\\Uploads\\PI-01\\producto_mod.csv', index=False)\n",
    "df_sucursal.to_csv(r'C:\\ProgramData\\MySQL\\MySQL Server 8.0\\Uploads\\PI-01\\sucursal_mod.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a2a52aef931fcd23a480fc50f39afd0b17785c85069eee4875d92629a01f91b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
